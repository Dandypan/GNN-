import torch
from sklearn.cluster import KMeans
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATv2Conv, GINConv
from torch_geometric.data import Data
from sklearn.metrics import accuracy_score, f1_score
import pandas as pd
import matplotlib.pyplot as plt


class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()



def load_email_communication_network(file_path):
    edges = pd.read_csv(file_path, sep='\t', comment='#', header=None, names=['sender', 'receiver'])
    edges.dropna(subset=['sender', 'receiver'], inplace=True)
    edges['sender'] = edges['sender'].astype(int)
    edges['receiver'] = edges['receiver'].astype(int)

    senders = set(edges['sender'])
    receivers = set(edges['receiver'])
    sender_to_idx = {sender: idx for idx, sender in enumerate(senders)}
    receiver_to_idx = {receiver: idx + len(senders) for idx, receiver in enumerate(receivers)}

    edge_index = []
    for _, row in edges.iterrows():
        u = sender_to_idx[row['sender']]
        v = receiver_to_idx[row['receiver']]
        edge_index.append([u, v])
        edge_index.append([v, u])

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    num_nodes = len(senders) + len(receivers)

    data = Data(edge_index=edge_index)
    return data



def generate_node_features_with_pseudo_labels(data, num_clusters):
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans.fit(data.edge_index.t().cpu().numpy())
    pseudo_labels = torch.tensor(kmeans.labels_, dtype=torch.long)
    one_hot_features = F.one_hot(pseudo_labels, num_classes=num_clusters).float()
    return one_hot_features



class CustomGNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_gatv2_layers, num_gin_layers, gat_heads=8, dropout=0.5):
        super(CustomGNNModel, self).__init__()
        self.convs = nn.ModuleList()
        self.batch_norms = nn.ModuleList()
        self.residual_projs = nn.ModuleList()  # Projection layers for residuals

        current_dim = input_dim

        
        for _ in range(num_gatv2_layers):
            self.convs.append(GATv2Conv(current_dim, hidden_dim // gat_heads, heads=gat_heads, dropout=dropout))
            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))
            self.residual_projs.append(nn.Linear(current_dim, hidden_dim))
            current_dim = hidden_dim

        
        for _ in range(num_gin_layers):
            self.convs.append(GINConv(nn.Linear(current_dim, hidden_dim)))
            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))
            self.residual_projs.append(nn.Linear(current_dim, hidden_dim) if current_dim != hidden_dim else nn.Identity())
            current_dim = hidden_dim

        
        self.fc = nn.Linear(current_dim, output_dim)
        self.dropout = nn.Dropout(p=dropout)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        for i in range(len(self.convs)):
            residual = self.residual_projs[i](x)
            x = self.convs[i](x, edge_index)
            x = self.batch_norms[i](x)
            x = F.relu(x) + residual
            x = self.dropout(x)
        return self.fc(x)



def train_gnn_model_with_regularization(model, data, epochs=60, lr=0.01, weight_decay=1e-4):
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    criterion = FocalLoss()

    accuracies, f1_scores = [], []

    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        out = model(data)
        loss = criterion(out, data.pseudo_labels)
        loss.backward()
        optimizer.step()

        
        model.eval()
        with torch.no_grad():
            preds = out.argmax(dim=1)
            acc = accuracy_score(data.pseudo_labels.cpu(), preds.cpu())
            f1 = f1_score(data.pseudo_labels.cpu(), preds.cpu(), average="macro")
            accuracies.append(acc)
            f1_scores.append(f1)

        print(f"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {acc:.4f}, F1 Score: {f1:.4f}")

    return accuracies, f1_scores



def plot_layer_analysis(results):
    epochs = range(1, 61)  # 60 epochs
    plt.figure(figsize=(16, 6))

    
    plt.subplot(1, 2, 1)
    for label, (acc, _) in results.items():
        plt.plot(epochs, acc, label=f"{label} Accuracy")
    plt.title("Accuracy Comparison")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()

    
    plt.subplot(1, 2, 2)
    for label, (_, f1) in results.items():
        plt.plot(epochs, f1, label=f"{label} F1 Score")
    plt.title("F1 Score Comparison")
    plt.xlabel("Epochs")
    plt.ylabel("F1 Score")
    plt.legend()

    plt.tight_layout()
    plt.show()



if __name__ == "__main__":
    file_path = "/content/drive/MyDrive/email-Enron/email-Enron.txt"
    data = load_email_communication_network(file_path)

    
    num_clusters = 4
    data.x = generate_node_features_with_pseudo_labels(data, num_clusters)

    
    data.pseudo_labels = generate_pseudo_labels(data.x, num_clusters)

    results = {}

    total_layers = 6  # Fixed total number of layers
    for num_gatv2_layers in range(total_layers + 1):  # Vary GATv2 layers
        num_gin_layers = total_layers - num_gatv2_layers  # Remaining layers are GIN
        label = f"GATv2: {num_gatv2_layers}, GIN: {num_gin_layers}"
        print(f"\n===== {label} =====")
        model = CustomGNNModel(input_dim=num_clusters, hidden_dim=128, output_dim=num_clusters,
                               num_gatv2_layers=num_gatv2_layers, num_gin_layers=num_gin_layers)
        acc, f1 = train_gnn_model_with_regularization(model, data, epochs=60)
        results[label] = (acc, f1)

    
    plot_layer_analysis(results)
